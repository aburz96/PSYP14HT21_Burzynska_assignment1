---
title: "Assignment 1 ZK"
author: "Aleksandra Burzynska"
date: "11/21/2021"

---

##  Assignment part 1
## import data  sample 1
```{r}
data_sample_1 =read.csv("https://tinyurl.com/ha-dataset1")
head(data_sample_1)
nrow(data_sample_1)
names(data_sample_1)
```
## Model 1
```{r}
Model_1<-lm(pain~age+sex,data=data_sample_1)
summary(Model_1)
summary(Model_1)$adj.r.squared
AIC(Model_1)
anova(Model_1)
confint(Model_1)
```
##  Model 2

```{r}
Model_2<-lm(pain~age+sex+STAI_trait+pain_cat+mindfulness+cortisol_serum+cortisol_saliva,data=data_sample_1)
summary(Model_2)
summary(Model_2)$adj.r.squared
AIC(Model_2)
anova(Model_2)
confint(Model_2)

```

## check the out outliers

```{r}
library(tidyverse)
library(broom)
model.diag.metrics<-augment(Model_1)
head(model.diag.metrics)
ggplot(model.diag.metrics, aes(age, pain)) +
  geom_point() +
  stat_smooth(method = lm, se = FALSE) +
  geom_segment(aes(xend = age, yend = .fitted), color = "red", size = 0.3)


```


##  Assumptions of linear regression
##Normality of residuals
```{r}
plot(Model_1, 2)

plot(Model_2, 2)

```

The QQ plot of residuals can be used to visually check the normality assumption. The normal probability plot of residuals should approximately follow a straight line.
In our example, all the points fall approximately along this reference line, so we can assume normality.

## Linearity of the data
```{r}
plot(Model_1, 1)
plot(Model_2, 1)

```

Ideally, the residual plot will show no fitted pattern. That is, the red line should be approximately horizontal at zero. The presence of a pattern may indicate a problem with some aspect of the linear model.

## Homogeneity of variance
```{r}
plot(Model_1,3)
plot(Model_2,3)


```

This plot shows if residuals are spread equally along the ranges of predictors. It’s good if you see a horizontal line with equally spread points. In our example, this is not the case.

##  Multicollinearity in data sets
```{r}
car::vif(Model_1)
car::vif(Model_2)

```

Here all values of VIF is less than 5 so multicollinearity does not exist in this data set
##  Assignment part 2

```{r}
data_sample_1 =read.csv("https://tinyurl.com/ha-dataset1")
head(data_sample_1)
nrow(data_sample_1)
names(data_sample_1)

```
## Stepwise regression model 1
```{r}
fullmodel_1  <-lm(pain~age+sex+STAI_trait+pain_cat+mindfulness+cortisol_serum+weight+IQ+household_income, data =data_sample_1)
model_1<-step(fullmodel_1, direction = "backward", trace=FALSE )
summary(model_1)
library(car)
library(lattice)
library(carData)
library(caret)
durbinWatsonTest(model_1)
anova(model_1)
confint(model_1)
AIC(model_1)
car::vif(model_1)

```
##  Stepwise regression model2 using new data

```{r}
data_sample_2 =read.csv("https://tinyurl.com/87v6emky")
head(data_sample_2)
names(data_sample_2)
```

## stepwise Regression Model2 using new data
```{r}
fullmodel_2  <-lm(pain~age+sex+STAI_trait+pain_cat+mindfulness+cortisol_serum+weight+IQ+household_income, data =data_sample_2)
model_2<-step(fullmodel_2, direction = "backward", trace=FALSE )
summary(model_2)
anova(model_2)
AIC(model_2)
car::vif(model_2)
```

##  Assignment part 3

```{r}
data_file_3=read.csv("https://tinyurl.com/b385chpu")
data_file_4=read.csv("https://tinyurl.com/4f8thztv")
names(data_file_3)
str(data_file_3)
head(data_file_3)
```
##  Fitt a mixed model
```{r}
 library(Matrix)
 library(lme4)
library(Rcpp)
mixed.lmer<-lmer(pain~sex+age+(1|hospital),data_file_3)
summary(mixed.lmer)
anova(mixed.lmer)
AIC(mixed.lmer)
BIC(mixed.lmer)

```
We can see the variance for hospital = 0.1631. hospital id  is clearly important: they explain a lot of variation. How do we know that? We can take the variance for the hospital id and divide it by the total variance:

## variance

```{r}
variance<-0.1631/(0.1631+1.7778)
variance
```
So the differences between hospital id explain ~8.4% of the variance that’s “left over” after the variance explained by our fixed effects

## R square

```{r}
RSS<-1.7778
TSS<-1.7778+0.1631
R_Square<-1-(RSS/TSS)
R_Square
```


## As always, it’s good practice to have a look at the plots to check our assumptions:
```{r}
plot(mixed.lmer)  # looks alright, no patterns evident

```


##  Q plot
```{r}
qqnorm(resid(mixed.lmer))
qqline(resid(mixed.lmer)) 

```


##  Plotting model predictions

```{r}
library(ggeffects)
mixed.lmer2<-lmer(pain~sex+age++STAI_trait+pain_cat+mindfulness+cortisol_serum+cortisol_saliva+(1|hospital),data_file_3)
summary(mixed.lmer2)
anova(mixed.lmer2)
AIC(mixed.lmer2)
BIC(mixed.lmer2)

```

## R square
```{r}
RSS<-0.1771
TSS<-0.1771+1.2055
R_Square<-1-(RSS/TSS)
R_Square
```

##  prediction
```{r}
predict1<- predict(mixed.lmer)
predict1
predict2<- predict(mixed.lmer2)
predict2
```
